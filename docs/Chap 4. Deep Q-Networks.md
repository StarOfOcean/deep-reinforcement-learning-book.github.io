---
layout: default
title: Chap 4. Deep Q-Networks
nav_order: 5
lang: en
---

## Authors

- Yanhua Huang* - Xiaohongshu Technology Co. (iofficium[at]gmail.com)

## Abstract

This chapter aims to introduce one of the most important deep reinforcement learning algorithms, called deep Q-networks. We will start with the Q-learning algorithm via temporal difference learning, and introduce the deep Q-networks algorithm and its variants. We will end this chapter with code examples and experimental comparison of deep Q-networks and its variants in practice.

**Keywords**: temporal difference learning, DQN, double DQN, dueling DQN, prioritized experience replay, distributional reinforcement learning

## Content
[中文版PDF](/assets/pdfs/ch4.pdf){: .btn .btn-purple  .fs-3 .mb-4 .mb-md-0 .mr-2 }

## Code 

Codes for contents in this chapter are available [**here**](https://github.com/deep-reinforcement-learning-book/Chapter4-DQN).

## Citation

To cite this book, please use this bibtex entry:

```
@incollection{deepRL-chapter4-2020,
 title={Deep Q-Networks},
 chapter={4},
 author={Yanhua Huang},
 editor={Hao Dong, Zihan Ding, Shanghang Zhang},
 booktitle={Deep Reinforcement Learning: Fundamentals, Research, and Applications},
 publisher={Springer Nature},
 pages={135-160},
 note={\url{http://www.deepreinforcementlearningbook.org}},
 year={2020}
}
```





If you find any typos or have suggestions for improving the book, do not hesitate to contact with the corresponding author (name with *).